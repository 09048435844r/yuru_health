import json
import yaml
import streamlit as st
from typing import Dict, Any, Optional, List
from pathlib import Path
from src.evaluators.base_evaluator import BaseEvaluator
from src.utils.secrets_loader import load_secrets

try:
    import google.generativeai as genai
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False


class GeminiEvaluator(BaseEvaluator):
    """
    Google Gemini APIã‚’ä½¿ç”¨ã—ãŸå¥åº·ãƒ‡ãƒ¼ã‚¿è©•ä¾¡ã‚¯ãƒ©ã‚¹
    """
    
    def __init__(self, config: Dict[str, Any], secrets_path: str = "config/secrets.yaml", 
                 settings_path: str = "config/settings.yaml", prompts_path: str = "config/prompts.yaml", 
                 model_name: Optional[str] = None):
        super().__init__(config)
        self.secrets_path = Path(secrets_path)
        self.settings_path = Path(settings_path)
        self.prompts_path = Path(prompts_path)
        self.api_key = self._load_api_key()
        self.model_name = model_name or self._load_model_name()
        self.prompts = self._load_prompts()
        self.model = None
        self._initialize_model()
    
    def _load_api_key(self) -> Optional[str]:
        """Gemini APIã‚­ãƒ¼ã‚’èª­ã¿è¾¼ã‚€"""
        try:
            secrets = load_secrets(str(self.secrets_path))
            return secrets.get("gemini", {}).get("api_key")
        except Exception:
            return None
    
    def _load_model_name(self) -> str:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«åã‚’èª­ã¿è¾¼ã‚€"""
        try:
            with open(self.settings_path, "r", encoding="utf-8") as f:
                settings = yaml.safe_load(f)
                return settings.get("gemini", {}).get("model_name", "gemini-1.5-flash")
        except Exception:
            return "gemini-1.5-flash"
    
    def _load_prompts(self) -> Dict[str, str]:
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã‚€"""
        try:
            with open(self.prompts_path, "r", encoding="utf-8") as f:
                prompts_data = yaml.safe_load(f)
                return prompts_data
        except Exception:
            return {
                "logical": {
                    "template": "å¥åº·ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã¦ãã ã•ã„ï¼š{weight_summary}\n{oura_summary}"
                },
                "witty": {
                    "template": "å¥åº·ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ¦ãƒ¼ãƒ¢ã‚¢ã‚’äº¤ãˆã¦åˆ†æã—ã¦ãã ã•ã„ï¼š{weight_summary}\n{oura_summary}"
                }
            }
    
    def _initialize_model(self):
        """Geminiãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ã™ã‚‹"""
        if GENAI_AVAILABLE and self.api_key:
            try:
                genai.configure(api_key=self.api_key)
                self.model = genai.GenerativeModel(self.model_name)
            except Exception:
                pass
    
    @staticmethod
    def _load_user_profile() -> Dict[str, str]:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã‚’ st.secrets ã‹ã‚‰èª­ã¿è¾¼ã‚€"""
        try:
            profile = st.secrets.get("user_profile", {})
        except Exception:
            profile = {}
        return {
            "age": profile.get("age", "ä¸æ˜"),
            "gender": profile.get("gender", "ä¸æ˜"),
            "location": profile.get("location", "ä¸æ˜"),
            "occupation": profile.get("occupation", "ä¸æ˜"),
            "concerns": profile.get("concerns", "ç‰¹ã«ãªã—"),
            "goals": profile.get("goals", "å¥åº·ç¶­æŒ"),
        }

    def is_available(self) -> bool:
        """è©•ä¾¡æ©Ÿèƒ½ãŒåˆ©ç”¨å¯èƒ½ã‹ç¢ºèª"""
        return GENAI_AVAILABLE and self.model is not None and self.api_key is not None
    
    def evaluate(self, data: Dict[str, Any], mode: str = "logical") -> str:
        """
        å¥åº·ãƒ‡ãƒ¼ã‚¿ã‚’è©•ä¾¡ã—ã¦ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆ
        
        Args:
            data: è©•ä¾¡å¯¾è±¡ã®å¥åº·ãƒ‡ãƒ¼ã‚¿
            mode: è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ï¼ˆlogical / wittyï¼‰
            
        Returns:
            str: ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ†ã‚­ã‚¹ãƒˆ
        """
        if not self.is_available():
            return "âš ï¸ Gemini APIãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
        
        prompt = self._build_prompt(data, mode)
        
        try:
            response = self.model.generate_content(prompt)
            return response.text
        except Exception as e:
            return f"âŒ è©•ä¾¡ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
    
    def _build_prompt(self, data: Dict[str, Any], mode: str) -> str:
        """
        è©•ä¾¡ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
        
        Args:
            data: å¥åº·ãƒ‡ãƒ¼ã‚¿
            mode: è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰
            
        Returns:
            str: æ§‹ç¯‰ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        """
        weight_summary = self._format_weight_data(data.get("weight_data", []))
        oura_summary = self._format_oura_data(data.get("oura_data", []))
        
        if mode not in self.prompts:
            raise ValueError(f"Unknown mode: {mode}")
        
        template = self.prompts[mode].get("template", "")
        
        return template.format(
            weight_summary=weight_summary,
            oura_summary=oura_summary
        )
    
    def _format_weight_data(self, weight_data: list) -> str:
        """ä½“é‡ãƒ‡ãƒ¼ã‚¿ã‚’æ•´å½¢"""
        if not weight_data:
            return "ä½“é‡ãƒ‡ãƒ¼ã‚¿: ãªã—"
        
        latest = weight_data[0] if weight_data else None
        if latest:
            return f"""ä½“é‡ãƒ‡ãƒ¼ã‚¿:
- æœ€æ–°ä½“é‡: {latest.get('weight_kg', 'N/A')}kg ({latest.get('measured_at', 'N/A')})
- ç›´è¿‘7æ—¥å¹³å‡: {self._calculate_average(weight_data[:7], 'weight_kg'):.1f}kg
- ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(weight_data)}ä»¶"""
        return "ä½“é‡ãƒ‡ãƒ¼ã‚¿: åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ãªã—"
    
    def _format_oura_data(self, oura_data: list) -> str:
        """Ouraãƒ‡ãƒ¼ã‚¿ã‚’æ•´å½¢"""
        if not oura_data:
            return "Ouraãƒ‡ãƒ¼ã‚¿: ãªã—"
        
        latest = oura_data[0] if oura_data else None
        if latest:
            return f"""Oura Ringãƒ‡ãƒ¼ã‚¿:
- æ´»å‹•ã‚¹ã‚³ã‚¢: {latest.get('activity_score', 'N/A')}ç‚¹
- ç¡çœ ã‚¹ã‚³ã‚¢: {latest.get('sleep_score', 'N/A')}ç‚¹
- ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ã‚¹ã‚³ã‚¢: {latest.get('readiness_score', 'N/A')}ç‚¹
- æ­©æ•°: {latest.get('steps', 'N/A')}æ­©
- æ¸¬å®šæ—¥: {latest.get('measured_at', 'N/A')}
- ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(oura_data)}ä»¶"""
        return "Oura Ringãƒ‡ãƒ¼ã‚¿: åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ãªã—"
    
    def _calculate_average(self, data: list, key: str) -> float:
        """å¹³å‡å€¤ã‚’è¨ˆç®—"""
        values = [item.get(key, 0) for item in data if item.get(key) is not None]
        return sum(values) / len(values) if values else 0
    
    def deep_analyze(self, raw_data_dict: Optional[Dict[str, List[Dict[str, Any]]]] = None,
                     target_model: Optional[str] = None, **kwargs) -> str:
        """
        Data Lake ã®ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒ­ã‚¹åˆ†æã™ã‚‹ Deep Insight æ©Ÿèƒ½
        
        Args:
            raw_data_dict: source ã‚’ã‚­ãƒ¼ã¨ã—ãŸç”Ÿãƒ‡ãƒ¼ã‚¿è¾æ›¸
                           ä¾‹: {'oura': [...], 'withings': [...], 'weather': [...]} 
            target_model: ä½¿ç”¨ã™ã‚‹ Gemini ãƒ¢ãƒ‡ãƒ«åã€‚None ã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã€‚
        
        Returns:
            str: AI ã«ã‚ˆã‚‹æ·±å±¤åˆ†æãƒ†ã‚­ã‚¹ãƒˆ
        """
        if not self.is_available():
            return "âš ï¸ Gemini APIãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"

        # å‘¼ã³å‡ºã—å´äº’æ›: raw_data ã‚­ãƒ¼ã§æ¸¡ã•ã‚ŒãŸå ´åˆã‚‚å—ã‘ä»˜ã‘ã‚‹
        if raw_data_dict is None and isinstance(kwargs.get("raw_data"), dict):
            raw_data_dict = kwargs.get("raw_data")
        
        if not raw_data_dict:
            return "âš ï¸ åˆ†æå¯¾è±¡ã®ç”Ÿãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã¾ãšğŸ”„ãƒœã‚¿ãƒ³ã§ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°ã—ã¦ãã ã•ã„ã€‚"
        
        # target_model ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚Œã°ãã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã€ãªã‘ã‚Œã°ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        model = self.model
        if target_model and target_model != self.model_name:
            try:
                model = genai.GenerativeModel(target_model)
            except Exception:
                model = self.model
        
        profile = self._load_user_profile()

        data_sections = []
        for source, records in raw_data_dict.items():
            payloads = [r.get("payload", {}) for r in records]
            data_sections.append(f"### {source.upper()} (ä»¶æ•°: {len(records)})\n```json\n{json.dumps(payloads, ensure_ascii=False, indent=1, default=str)}\n```")
        
        raw_data_text = "\n\n".join(data_sections)
        
        prompt = f"""ã‚ãªãŸã¯ã€ä»¥ä¸‹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å°‚å±ãƒ˜ãƒ«ã‚¹ã‚³ãƒ¼ãƒã§ã™ã€‚

ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã€‘
- å¹´é½¢: {profile['age']}
- æ€§åˆ¥: {profile['gender']}
- å±…ä½åœ°: {profile['location']}
- è·æ¥­: {profile['occupation']}
- ç¾åœ¨ã®æ‚©ã¿: {profile['concerns']}
- ç›®æ¨™: {profile['goals']}

ã€ç›´è¿‘ã®å¥åº·ãƒ‡ãƒ¼ã‚¿ã€‘
{raw_data_text}

ã€ä¾é ¼ã€‘
ä¸Šè¨˜ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ‚©ã¿ã‚„ç›®æ¨™ã«å¯„ã‚Šæ·»ã£ãŸã€å…·ä½“çš„ã‹ã¤å®Ÿè·µçš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’3ç‚¹æç¤ºã—ã¦ãã ã•ã„ã€‚
ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ãŸã€Œæ°—ã¥ãã€ã¨ã€ç„¡ç†ãªãã§ãã‚‹ã€Œå°ã•ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚
å£èª¿ã¯ãƒ•ãƒ©ãƒ³ã‚¯ã§è¦ªã—ã¿ã‚„ã™ãã€åŠ±ã¾ã™ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚"""
        
        try:
            response = model.generate_content(prompt)
            return response.text
        except Exception as e:
            return f"âŒ Deep Insight åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
